# ü§ñ CLAUDE API OPTIMIZATION

**Date**: 12 Februari 2026
**Issue**: Token limits yang terlalu tinggi/tidak perlu
**Status**: ‚úÖ **OPTIMIZED**

---

## üéØ CHANGES MADE

### Files Updated:
1. ‚úÖ **step1-chronicle-analyzer.ts**
2. ‚úÖ **step3-question-generator.ts**

---

## üìä BEFORE vs AFTER

### step1-chronicle-analyzer.ts

**BEFORE**:
```typescript
body: JSON.stringify({
  model: CLAUDE_MODEL,
  max_tokens: 16000, // ‚ùå Too high for structured JSON
  temperature: 0.3,
  messages: [{ role: 'user', content: prompt }]
})
```

**AFTER**:
```typescript
body: JSON.stringify({
  model: CLAUDE_MODEL,
  max_tokens: 8192, // ‚úÖ Optimal for structured output
  temperature: 0.3,
  messages: [{ role: 'user', content: prompt }]
})
```

**Why Changed**:
- Chronicle output adalah structured JSON (~2-4K tokens)
- 16K adalah overkill untuk structured response
- 8K cukup untuk comprehensive brand DNA
- Cost savings: ~50% reduction in max output

---

### step3-question-generator.ts

**BEFORE**:
```typescript
body: JSON.stringify({
  model: CLAUDE_MODEL,
  max_tokens: 16000, // ‚ùå Too high
  temperature: 0.4,  // ‚ùå Too high for questions
  messages: [{ role: 'user', content: prompt }]
})
```

**AFTER**:
```typescript
body: JSON.stringify({
  model: CLAUDE_MODEL,
  max_tokens: 8192,  // ‚úÖ Optimal for 50 questions
  temperature: 0.2,  // ‚úÖ Lower for consistency
  messages: [{ role: 'user', content: prompt }]
})
```

**Why Changed**:
- 50 questions dengan metadata = ~3-5K tokens
- 16K terlalu tinggi, menghasilkan output yang tidak perlu panjang
- Temperature 0.4 ‚Üí 0.2: Questions harus konsisten, bukan kreatif
- Cost savings: ~50% reduction + better quality

---

## üí∞ COST IMPACT

### Claude Sonnet 4 Pricing:
- **Input**: $3.00 per 1M tokens
- **Output**: $15.00 per 1M tokens

### Step 1 (Chronicle):
**Before** (16K max):
- Typical output: 3K tokens
- Billed for: 3K tokens
- Cost per request: ~$0.045

**After** (8K max):
- Typical output: 3K tokens (same)
- Billed for: 3K tokens (same)
- Cost per request: ~$0.045 (same)

**Note**: Actual output sama, jadi cost tidak berubah. Tapi max_tokens lebih reasonable.

### Step 3 (Questions):
**Before** (16K max):
- Typical output: 4K tokens
- Billed for: 4K tokens
- Cost per request: ~$0.06

**After** (8K max):
- Typical output: 4K tokens (same)
- Billed for: 4K tokens (same)
- Cost per request: ~$0.06 (same)

**Combined Savings**: $0 (output sama, tapi limit lebih aman)

---

## ‚úÖ BENEFITS

### 1. **Appropriate Limits**
- 16K terlalu tinggi untuk structured JSON
- 8K masih sangat cukup untuk output yang diharapkan
- Prevents unnecessary verbose output

### 2. **Better Quality (Step 3)**
- Temperature 0.4 ‚Üí 0.2
- Questions lebih konsisten
- Less variation = more predictable output

### 3. **Safety**
- Prevents runaway token usage
- Claude won't generate 16K tokens of unnecessary fluff
- Better control over output length

### 4. **Cost Protection**
- Max tokens acts as safety limit
- Prevents unexpected high bills
- More predictable cost per request

---

## üîç CLAUDE API BEST PRACTICES

### For Structured Output (JSON):
```typescript
max_tokens: 4096 - 8192
temperature: 0.1 - 0.3
```
- Structured output tidak perlu banyak tokens
- Low temperature untuk konsistensi

### For Creative Content:
```typescript
max_tokens: 8192 - 16384
temperature: 0.6 - 0.9
```
- Konten kreatif butuh lebih banyak tokens
- Higher temperature untuk variasi

### For Long-form Content:
```typescript
max_tokens: 16384 - 32768
temperature: 0.4 - 0.7
```
- Artikel panjang, essays, reports
- Medium temperature

---

## üìã CLAUDE SONNET 4 SPECS

**Model**: `claude-sonnet-4-20250514`

**Limits**:
- Input context: 200K tokens
- Output max: 8192 tokens (default)
- Output max (with parameter): up to 16384 tokens

**Pricing** (as of Feb 2026):
- Input: $3.00 per 1M tokens
- Output: $15.00 per 1M tokens
- Prompt caching: 90% discount on cached input

---

## üö´ WHAT WE DIDN'T CHANGE

### ‚ùå TIDAK menghapus max_tokens
Alasan:
- max_tokens adalah safety mechanism
- Prevents runaway costs
- Provides predictable behavior
- Required by Claude API

### ‚ùå TIDAK set ke unlimited
Alasan:
- Claude API requires max_tokens parameter
- Unlimited bisa cost overruns
- Structured output tidak perlu unlimited

### ‚úÖ Set ke reasonable limit
- 8192 tokens cukup untuk:
  - Complete brand DNA (~2-4K tokens)
  - 50 questions dengan metadata (~3-5K tokens)
  - Comprehensive structured JSON
  - Safety margin untuk variasi

---

## üìä TOKEN USAGE ESTIMATES

### Step 1 - Chronicle Analyzer:

**Input** (~5-8K tokens):
- Prompt + instructions: ~500 tokens
- Brand data (10 insights): ~2K tokens
- Reviews (15): ~2K tokens
- Social signals (10): ~1.5K tokens
- Search data: ~500 tokens

**Output** (~2-4K tokens):
- brand_dna: ~800 tokens
- business_model: ~600 tokens
- competitive_position: ~600 tokens
- customer_profile: ~600 tokens
- brand_narrative: ~400 tokens
- Other fields: ~200 tokens

**Total**: ~10-12K tokens per request
**Cost**: ~$0.20-$0.25 per brand

---

### Step 3 - Question Generator:

**Input** (~6-8K tokens):
- Prompt + instructions: ~800 tokens
- Brand DNA: ~1K tokens
- Platform research: ~2K tokens
- Chronicle: ~2K tokens
- Question schema: ~500 tokens

**Output** (~3-5K tokens):
- 50 questions √ó ~80 tokens each = ~4K tokens
- Metadata: ~500 tokens

**Total**: ~11-13K tokens per request
**Cost**: ~$0.20-$0.30 per brand

---

## üéØ RECOMMENDATIONS

### Current Settings (OPTIMAL):

1. **step1-chronicle-analyzer.ts**:
   - max_tokens: 8192 ‚úÖ
   - temperature: 0.3 ‚úÖ

2. **step3-question-generator.ts**:
   - max_tokens: 8192 ‚úÖ
   - temperature: 0.2 ‚úÖ (improved from 0.4)

### Future Optimizations:

1. **Enable Prompt Caching** (90% cost savings):
   ```typescript
   headers: {
     'anthropic-version': '2023-06-01',
     'anthropic-cache': 'true' // Enable caching
   }
   ```

2. **Reduce Input Size**:
   - Limit insights to top 5 (not 10)
   - Limit reviews to top 10 (not 15)
   - Summarize social signals
   - **Potential savings**: 30-40% input cost

3. **Batch Processing**:
   - Process multiple brands in parallel
   - Share common context
   - **Potential savings**: 20% via efficiency

---

## ‚úÖ SUMMARY

### Changes Made:
- ‚úÖ step1: max_tokens 16000 ‚Üí 8192
- ‚úÖ step3: max_tokens 16000 ‚Üí 8192
- ‚úÖ step3: temperature 0.4 ‚Üí 0.2

### Benefits:
- ‚úÖ More appropriate token limits
- ‚úÖ Better quality output (step3)
- ‚úÖ Cost protection
- ‚úÖ Predictable behavior

### Cost Impact:
- No immediate savings (output size unchanged)
- Better cost protection (prevents overruns)
- Safety: max_tokens acts as ceiling

### Next Steps:
1. Enable prompt caching (90% savings)
2. Optimize input size (30-40% savings)
3. Monitor actual token usage
4. Adjust limits if needed

---

**Claude API optimization complete!** ‚úÖ
